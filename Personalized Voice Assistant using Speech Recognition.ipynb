{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d91469a",
   "metadata": {},
   "source": [
    "CONVERTING SPEECH TO TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0933c5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Say something:\n",
      "You said: \n",
      "I am Dhanush\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "recording = sr.Recognizer()\n",
    "with sr.Microphone() as source: \n",
    "    recording.adjust_for_ambient_noise(source)\n",
    "    print(\"Please Say something:\")\n",
    "    audio = recording.listen(source)\n",
    "try:\n",
    "    print(\"You said: \\n\" + recording.recognize_google(audio))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#listen words(speech) and gives it as text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac8215",
   "metadata": {},
   "source": [
    "TEXT TO SPEECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "996bf2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaking.....\n",
      "converted....\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "r = sr.Recognizer()\n",
    "def SpeakText(command):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command)\n",
    "    engine.runAndWait()\n",
    "print(\"speaking.....\")\n",
    "SpeakText(\"hello i am Robo,  speed 1 tera hertz, memory 1 giga byte\")\n",
    "print(\"converted....\")\n",
    "#given text is converted into speech "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0c2a1",
   "metadata": {},
   "source": [
    "RECORDED SPEECH TO TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8679bb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Recording.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 29\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e) )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m sound \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecording.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m r \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mAudioFile(sound) \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m      9\u001b[0m     r\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting Audio To Text ..... \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\New folder\\lib\\site-packages\\speech_recognition\\__init__.py:241\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis audio source is already inside a context manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# attempt to read the file as WAV\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m \u001b[43mwave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_or_fileobject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (wave\u001b[38;5;241m.\u001b[39mError, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\New folder\\lib\\wave.py:509\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    507\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWave_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Wave_write(f)\n",
      "File \u001b[1;32m~\\New folder\\lib\\wave.py:159\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 159\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# else, assume it is an open file object already\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Recording.wav'"
     ]
    }
   ],
   "source": [
    "#Recording.wav\n",
    "def main():\n",
    "    sound = \"Recording.wav\"\n",
    " \n",
    "    r = sr.Recognizer()\n",
    " \n",
    " \n",
    "    with sr.AudioFile(sound) as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    " \n",
    " \n",
    "        print(\"Converting Audio To Text ..... \")\n",
    " \n",
    " \n",
    "        audio = r.listen(source)\n",
    " \n",
    " \n",
    " \n",
    "    try:\n",
    "        print(\"Converted Audio Is : \\n\" + r.recognize_google(audio))\n",
    " \n",
    " \n",
    "    except Exception as e:\n",
    "        print(\"Error {} : \".format(e) )\n",
    " \n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "#if we gives audio file which is in wave format then it converts the audio into text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48237c9c",
   "metadata": {},
   "source": [
    "Opening Website Using Speech Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0320b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please say something \n",
      "Recognizing Now ... \n",
      "You have said : youtube.com\n"
     ]
    }
   ],
   "source": [
    "import webbrowser as web\n",
    " \n",
    " \n",
    " \n",
    "def main():\n",
    " \n",
    "    path = 'C:/Program Files/Google/Chrome/Application/chrome.exe %s'\n",
    " \n",
    " \n",
    "    r = sr.Recognizer()\n",
    " \n",
    "    with sr.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    " \n",
    "        print(\"Please say something \")\n",
    " \n",
    "        audio = r.listen(source)\n",
    " \n",
    "        print(\"Recognizing Now ... \")\n",
    " \n",
    " \n",
    " \n",
    "        try:\n",
    "            dest = r.recognize_google(audio)\n",
    "            print(\"You have said : \" + dest)\n",
    " \n",
    "            web.get(path).open(dest)\n",
    " \n",
    "        except Exception as e:\n",
    "            print(\"Error : \" + str(e))\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "#say utube.com it will open utube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe3d2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr # recognise speech\n",
    "import playsound # to play an audio file\n",
    "from gtts import gTTS # google text to speech\n",
    "import random\n",
    "from time import ctime # get time details\n",
    "import webbrowser # open browser\n",
    "import time\n",
    "import os # to remove created audio files\n",
    "from PIL import Image\n",
    "#import subprocess\n",
    "import pyautogui #screenshot\n",
    "import pyttsx3\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfe85d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Listening\n",
      ">> \n",
      "Done\n",
      "Q: \n",
      "Done Listening\n",
      ">> what is your name\n",
      "Done\n",
      "Q: what is your name\n",
      "Done Listening\n",
      ">> \n",
      "Done\n",
      "Q: \n",
      "Done Listening\n",
      ">> \n",
      "Done\n",
      "Q: \n",
      "Done Listening\n",
      ">> my name is dhanush\n",
      "Done\n",
      "Q: my name is dhanush\n",
      "Done Listening\n",
      ">> \n",
      "Done\n",
      "Q: \n",
      "Done Listening\n",
      ">> microphone\n",
      "Done\n",
      "Q: microphone\n",
      "Done Listening\n",
      ">> what is my name\n",
      "Done\n",
      "Q: what is my name\n",
      "Done Listening\n",
      ">> what's the time\n",
      "Done\n",
      "Q: what's the time\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 244\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ:\u001b[39m\u001b[38;5;124m\"\u001b[39m, voice_data)\n\u001b[1;32m--> 244\u001b[0m \u001b[43mrespond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoice_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 91\u001b[0m, in \u001b[0;36mrespond\u001b[1;34m(voice_data)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     hours \u001b[38;5;241m=\u001b[39m time[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 91\u001b[0m minutes \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     92\u001b[0m time \u001b[38;5;241m=\u001b[39m hours \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m minutes \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m engine_speak(time)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class person:\n",
    "    name = ''\n",
    "    def setName(self, name):\n",
    "        self.name = name\n",
    "\n",
    "class asis:\n",
    "    name = ''\n",
    "    def setName(self, name):\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "\n",
    "def there_exists(terms):\n",
    "    for term in terms:\n",
    "        if term in voice_data:\n",
    "            return True\n",
    "\n",
    "def engine_speak(text):\n",
    "    text = str(text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "r = sr.Recognizer() # initialise a recogniser\n",
    "# listen for audio and convert it to text:\n",
    "def record_audio(ask=\"\"):\n",
    "    with sr.Microphone() as source: # microphone as source\n",
    "        if ask:\n",
    "            engine_speak(ask)\n",
    "        audio = r.listen(source, 5, 5)  # listen for the audio via source\n",
    "        print(\"Done Listening\")\n",
    "        voice_data = ''\n",
    "        try:\n",
    "            voice_data = r.recognize_google(audio)  # convert audio to text\n",
    "        except sr.UnknownValueError: # error: recognizer does not understand\n",
    "            engine_speak('I did not get that')\n",
    "        except sr.RequestError:\n",
    "            engine_speak('Sorry, the service is down') # error: recognizer is not connected\n",
    "        print(\">>\", voice_data.lower()) # print what user said\n",
    "        return voice_data.lower()\n",
    "\n",
    "\n",
    "\n",
    "def respond(voice_data):\n",
    "    # 1: greeting\n",
    "    if there_exists(['hey','hi','hai','hello']):\n",
    "        greetings = [\"hey, how can I help you\" + person_obj.name, \"hey, what's up?\" + person_obj.name, \"I'm listening\" + person_obj.name, \"how can I help you?\" + person_obj.name, \"hello\" + person_obj.name]\n",
    "        greet = greetings[random.randint(0,len(greetings)-1)]\n",
    "        engine_speak(greet)\n",
    "\n",
    "    # 2: name\n",
    "    if there_exists([\"what is your name\",\"what's your name\",\"tell me your name\"]):\n",
    "\n",
    "        if person_obj.name:\n",
    "            engine_speak(f\"My name is {asis_obj.name}, {person_obj.name}\") #gets users name from voice input\n",
    "        else:\n",
    "            engine_speak(f\"My name is {asis_obj.name}. what's your name?\") #incase you haven't provided your name.\n",
    "\n",
    "    if there_exists([\"my name is\"]):\n",
    "        person_name = voice_data.split(\"is\")[-1].strip()\n",
    "        engine_speak(\"okay, i will remember that \" + person_name)\n",
    "        person_obj.setName(person_name) # remember name in person object\n",
    "    \n",
    "    if there_exists([\"what is my name\"]):\n",
    "        engine_speak(\"Your name must be \" + person_obj.name)\n",
    "    \n",
    "    if there_exists([\"nlp\"]):\n",
    "        engine_speak(\"Anitha mam\" )\n",
    "    \n",
    "    if there_exists([\"who are you\"]):\n",
    "        engine_speak(\" i am your assistant how can i help you\" )\n",
    "        \n",
    "    if there_exists([\"my project\"]):\n",
    "        engine_speak(\"Speech Recognition in NLP\" )\n",
    "    \n",
    "    if there_exists([\"your name should be\"]):\n",
    "        asis_name = voice_data.split(\"be\")[-1].strip()\n",
    "        engine_speak(\"okay, i will remember that my name is \" + asis_name)\n",
    "        asis_obj.setName(asis_name) # remember name in asis object\n",
    "\n",
    "    # 3: greeting\n",
    "    if there_exists([\"how are you\",\"how are you doing\"]):\n",
    "        engine_speak(\"I'm very well, thanks for asking \" + person_obj.name)\n",
    "\n",
    "    # 4: time\n",
    "    if there_exists([\"what's the time\",\"tell me the time\",\"what time is it\",\"what is the time\"]):\n",
    "        time = ctime().split(\" \")[3].split(\":\")[0:2]\n",
    "        if time[0] == \"00\":\n",
    "            hours = '12'\n",
    "        else:\n",
    "            hours = time[0]\n",
    "        minutes = time[1]\n",
    "        time = hours + \"  \" + minutes + \" \"\n",
    "        engine_speak(time)\n",
    "\n",
    "    # 5: search google\n",
    "    if there_exists([\"search for\"]) and 'youtube' not in voice_data:\n",
    "        search_term = voice_data.split(\"for\")[-1]\n",
    "        url = \"https://google.com/search?q=\" + search_term\n",
    "        webbrowser.get().open(url)\n",
    "        engine_speak(\"Here is what I found for\" + search_term + \"on google\")\n",
    "    \n",
    "    if there_exists([\"search\"]) and 'youtube' not in voice_data:\n",
    "        search_term = voice_data.replace(\"search\",\"\")\n",
    "        url = \"https://google.com/search?q=\" + search_term\n",
    "        webbrowser.get().open(url)\n",
    "        engine_speak(\"Here is what I found for\" + search_term + \"on google\")\n",
    "\n",
    "    # 6: search youtube\n",
    "    if there_exists([\"youtube\"]):\n",
    "        search_term = voice_data.split(\"for\")[-1]\n",
    "        search_term = search_term.replace(\"on youtube\",\"\").replace(\"search\",\"\")\n",
    "        url = \"https://www.youtube.com/results?search_query=\" + search_term\n",
    "        webbrowser.get().open(url)\n",
    "        engine_speak(\"Here is what I found for \" + search_term + \"on youtube\")\n",
    "\n",
    "     #7: get stock price\n",
    "    if there_exists([\"price of\"]):\n",
    "        search_term = voice_data.split(\"for\")[-1]\n",
    "        url = \"https://google.com/search?q=\" + search_term\n",
    "        webbrowser.get().open(url)\n",
    "        engine_speak(\"Here is what I found for \" + search_term + \" on google\")\n",
    "    \n",
    "\n",
    "\n",
    "     #8 time table\n",
    "    if there_exists([\"time table\"]):\n",
    "        im = Image.open(\"C:\\\\Users\\\\santo\\\\Downloads\\\\WhatsApp Image 2022-07-17 at 20.57.16.jpeg\")\n",
    "        im.show()\n",
    "    \n",
    "     #9 weather\n",
    "    if there_exists([\"weather\"]):\n",
    "        search_term = voice_data.split(\"for\")[-1]\n",
    "        url = \"https://www.google.com/search?sxsrf=ACYBGNSQwMLDByBwdVFIUCbQqya-ET7AAA%3A1578847393212&ei=oUwbXtbXDN-C4-EP-5u82AE&q=weather&oq=weather&gs_l=psy-ab.3..35i39i285i70i256j0i67l4j0i131i67j0i131j0i67l2j0.1630.4591..5475...1.2..2.322.1659.9j5j0j1......0....1..gws-wiz.....10..0i71j35i39j35i362i39._5eSPD47bv8&ved=0ahUKEwiWrJvwwP7mAhVfwTgGHfsNDxsQ4dUDCAs&uact=5\"\n",
    "        webbrowser.get().open(url)\n",
    "        engine_speak(\"Here is what I found for on google\")\n",
    "     \n",
    "\n",
    "     #10 stone paper scisorrs\n",
    "    if there_exists([\"game\"]):\n",
    "        voice_data = record_audio(\"choose among rock paper or scissor\")\n",
    "        moves=[\"rock\", \"paper\", \"scissor\"]\n",
    "    \n",
    "        cmove=random.choice(moves)\n",
    "        pmove=voice_data\n",
    "        \n",
    "\n",
    "        engine_speak(\"The computer chose \" + cmove)\n",
    "        engine_speak(\"You chose \" + pmove)\n",
    "        #engine_speak(\"hi\")\n",
    "        if pmove==cmove:\n",
    "            engine_speak(\"the match is draw\")\n",
    "        elif pmove== \"rock\" and cmove== \"scissor\":\n",
    "            engine_speak(\"Player wins\")\n",
    "        elif pmove== \"rock\" and cmove== \"paper\":\n",
    "            engine_speak(\"Computer wins\")\n",
    "        elif pmove== \"paper\" and cmove== \"rock\":\n",
    "            engine_speak(\"Player wins\")\n",
    "        elif pmove== \"paper\" and cmove== \"scissor\":\n",
    "            engine_speak(\"Computer wins\")\n",
    "        elif pmove== \"scissor\" and cmove== \"paper\":\n",
    "            engine_speak(\"Player wins\")\n",
    "        elif pmove== \"scissor\" and cmove== \"rock\":\n",
    "            engine_speak(\"Computer wins\")\n",
    "\n",
    "     #11 toss a coin\n",
    "    if there_exists([\"toss\",\"flip\",\"coin\"]):\n",
    "        moves=[\"head\", \"tails\"]   \n",
    "        cmove=random.choice(moves)\n",
    "        engine_speak(\"The computer chose \" + cmove)\n",
    "\n",
    "     #12 calc\n",
    "    if there_exists([\"plus\",\"minus\",\"multiply\",\"divide\",\"power\",\"+\",\"-\",\"*\",\"/\"]):\n",
    "        opr = voice_data.split()[1]\n",
    "\n",
    "        if opr == '+':\n",
    "            engine_speak(int(voice_data.split()[0]) + int(voice_data.split()[2]))\n",
    "        elif opr == '-':\n",
    "            engine_speak(int(voice_data.split()[0]) - int(voice_data.split()[2]))\n",
    "        elif opr == 'multiply' or 'x':\n",
    "            engine_speak(int(voice_data.split()[0]) * int(voice_data.split()[2]))\n",
    "        elif opr == 'divide':\n",
    "            engine_speak(int(voice_data.split()[0]) / int(voice_data.split()[2]))\n",
    "        elif opr == 'power':\n",
    "            engine_speak(int(voice_data.split()[0]) ** int(voice_data.split()[2]))\n",
    "        else:\n",
    "            engine_speak(\"Wrong Operator\")\n",
    "        \n",
    "     #13 screenshot\n",
    "    if there_exists([\"capture\",\"my screen\",\"screenshot\"]):\n",
    "        myScreenshot = pyautogui.screenshot()\n",
    "        myScreenshot.save('D:/screenshot/screen.png')\n",
    "    \n",
    "    \n",
    "     #14 to search wikipedia for definition\n",
    "    if there_exists([\"definition of\"]):\n",
    "        definition=record_audio(\"what do you need the definition of\")\n",
    "        url=urllib.request.urlopen('https://en.wikipedia.org/wiki/'+definition)\n",
    "        soup=bs.BeautifulSoup(url,'lxml')\n",
    "        definitions=[]\n",
    "        for paragraph in soup.find_all('p'):\n",
    "            definitions.append(str(paragraph.text))\n",
    "        if definitions:\n",
    "            if definitions[0]:\n",
    "                engine_speak('im sorry i could not find that definition, please try a web search')\n",
    "            elif definitions[1]:\n",
    "                engine_speak('here is what i found '+definitions[1])\n",
    "            else:\n",
    "                engine_speak ('Here is what i found '+definitions[2])\n",
    "        else:\n",
    "                engine_speak(\"im sorry i could not find the definition for \"+definition)\n",
    "\n",
    "\n",
    "    if there_exists([\"exit\", \"quit\", \"goodbye\"]):\n",
    "        engine_speak(\"bye\")\n",
    "        exit()\n",
    "\n",
    "    # Current city or region\n",
    "    if there_exists([\"where am i\"]):\n",
    "        Ip_info = requests.get('https://api.ipdata.co?api-key=test').json()\n",
    "        loc = Ip_info['region']\n",
    "        engine_speak(f\"You must be somewhere in {loc}\")    \n",
    "   \n",
    "   # Current location as per Google maps\n",
    "    if there_exists([\"what is my exact location\"]):\n",
    "        url = \"https://www.google.com/maps/search/Where+am+I+?/\"\n",
    "        webbrowser.get().open(url)\n",
    "        engine_speak(\"You must be somewhere near here, as per Google maps\")    \n",
    "\n",
    "\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "person_obj = person()\n",
    "asis_obj = asis()\n",
    "asis_obj.name = 'robo'\n",
    "person_obj.name = \"\"\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "while(1):\n",
    "    voice_data = record_audio(\"Recording\") # get the voice input\n",
    "    print(\"Done\")\n",
    "    print(\"Q:\", voice_data)\n",
    "    respond(voice_data) # respond\n",
    "    \n",
    "#here if u say hi it will responds to it,ask the name give ur name ask to open utube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b580f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b796c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d99191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34209450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e8bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45bbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
